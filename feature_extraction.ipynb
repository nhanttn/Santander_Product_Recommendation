{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dtype_ser(ser):\n",
    "    \n",
    "    if ser.dtype == int:\n",
    "        return ser.astype(np.int32)\n",
    "    \n",
    "    if ser.dtype == float:\n",
    "        return ser.astype(np.float32)\n",
    "    \n",
    "    if ser.dtype == np.object:\n",
    "        return ser.astype(\"category\")\n",
    "    \n",
    "    return ser\n",
    "    \n",
    "\n",
    "def change_dtype_df(df):\n",
    "    \"\"\"\n",
    "    change types of columns to reduce memory size\n",
    "    :param df: dataframe\n",
    "    :return df: dataframe\n",
    "    \"\"\"\n",
    "    df[\"fecha_dato\"] = pd.to_datetime(df[\"fecha_dato\"])\n",
    "    df[\"fecha_alta\"] = pd.to_datetime(df[\"fecha_alta\"])\n",
    "    \n",
    "    memory = df.memory_usage().sum() / 10**6\n",
    "    print(\"Memory usage before changing types %0.2f MB\" % memory)\n",
    "\n",
    "    for col in df.columns:\n",
    "        df[col] = change_dtype_ser(df[col])\n",
    "\n",
    "    memory = df.memory_usage().sum() / 10 ** 6\n",
    "    print(\"Memory usage after changing types %0.2f MB\" % memory)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = change_dtype_df(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INP_DIR = \"data/data_\"\n",
    "OUT_DIR1 = \"data/data1_\"\n",
    "OUT_DIR2 = \"data/data2_\"\n",
    "OUT_DIR3 = \"data/data3_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before changing types 10044.42 MB\n",
      "Memory usage after changing types 4858.46 MB\n",
      "Memory usage before changing types 148.74 MB\n",
      "Memory usage after changing types 63.23 MB\n"
     ]
    }
   ],
   "source": [
    "df_train = load_csv(os.path.join(INP_DIR, \"train_cleaned.csv\"))\n",
    "df_test = load_csv(os.path.join(INP_DIR, \"test_cleaned.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop this column becuase it is too imbalanced\n",
    "df_train = df_train.drop([\"ind_empleado\"], axis=1)\n",
    "df_test = df_test.drop([\"ind_empleado\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days of joining since the month data is recorded \n",
    "df_train[\"fecha_alta\"] = (df_train[\"fecha_alta\"] - df_train[\"fecha_dato\"]).dt.days\n",
    "df_test[\"fecha_alta\"] = (df_test[\"fecha_alta\"] - df_test[\"fecha_dato\"]).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum().sum(), df_test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13647309, 91), (929615, 19))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fecha_dato', 'ncodpers', 'pais_residencia', 'sexo', 'age',\n",
       "       'fecha_alta', 'ind_nuevo', 'antiguedad', 'indrel', 'indrel_1mes',\n",
       "       'tiprel_1mes', 'indresi', 'indext', 'canal_entrada', 'indfall',\n",
       "       'cod_prov', 'ind_actividad_cliente', 'renta', 'segmento',\n",
       "       'ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n",
       "       'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n",
       "       'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
       "       'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n",
       "       'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
       "       'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
       "       'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
       "       'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1',\n",
       "       'ind_ahor_fin_ult1_NEW_PUR', 'ind_aval_fin_ult1_NEW_PUR',\n",
       "       'ind_cco_fin_ult1_NEW_PUR', 'ind_cder_fin_ult1_NEW_PUR',\n",
       "       'ind_cno_fin_ult1_NEW_PUR', 'ind_ctju_fin_ult1_NEW_PUR',\n",
       "       'ind_ctma_fin_ult1_NEW_PUR', 'ind_ctop_fin_ult1_NEW_PUR',\n",
       "       'ind_ctpp_fin_ult1_NEW_PUR', 'ind_deco_fin_ult1_NEW_PUR',\n",
       "       'ind_deme_fin_ult1_NEW_PUR', 'ind_dela_fin_ult1_NEW_PUR',\n",
       "       'ind_ecue_fin_ult1_NEW_PUR', 'ind_fond_fin_ult1_NEW_PUR',\n",
       "       'ind_hip_fin_ult1_NEW_PUR', 'ind_plan_fin_ult1_NEW_PUR',\n",
       "       'ind_pres_fin_ult1_NEW_PUR', 'ind_reca_fin_ult1_NEW_PUR',\n",
       "       'ind_tjcr_fin_ult1_NEW_PUR', 'ind_valo_fin_ult1_NEW_PUR',\n",
       "       'ind_viv_fin_ult1_NEW_PUR', 'ind_nomina_ult1_NEW_PUR',\n",
       "       'ind_nom_pens_ult1_NEW_PUR', 'ind_recibo_ult1_NEW_PUR',\n",
       "       'ind_ahor_fin_ult1_PUR_OR_CANCEL', 'ind_aval_fin_ult1_PUR_OR_CANCEL',\n",
       "       'ind_cco_fin_ult1_PUR_OR_CANCEL', 'ind_cder_fin_ult1_PUR_OR_CANCEL',\n",
       "       'ind_cno_fin_ult1_PUR_OR_CANCEL', 'ind_ctju_fin_ult1_PUR_OR_CANCEL',\n",
       "       'ind_ctma_fin_ult1_PUR_OR_CANCEL', 'ind_ctop_fin_ult1_PUR_OR_CANCEL',\n",
       "       'ind_ctpp_fin_ult1_PUR_OR_CANCEL', 'ind_deco_fin_ult1_PUR_OR_CANCEL',\n",
       "       'ind_deme_fin_ult1_PUR_OR_CANCEL', 'ind_dela_fin_ult1_PUR_OR_CANCEL',\n",
       "       'ind_ecue_fin_ult1_PUR_OR_CANCEL', 'ind_fond_fin_ult1_PUR_OR_CANCEL',\n",
       "       'ind_hip_fin_ult1_PUR_OR_CANCEL', 'ind_plan_fin_ult1_PUR_OR_CANCEL',\n",
       "       'ind_pres_fin_ult1_PUR_OR_CANCEL', 'ind_reca_fin_ult1_PUR_OR_CANCEL',\n",
       "       'ind_tjcr_fin_ult1_PUR_OR_CANCEL', 'ind_valo_fin_ult1_PUR_OR_CANCEL',\n",
       "       'ind_viv_fin_ult1_PUR_OR_CANCEL', 'ind_nomina_ult1_PUR_OR_CANCEL',\n",
       "       'ind_nom_pens_ult1_PUR_OR_CANCEL', 'ind_recibo_ult1_PUR_OR_CANCEL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fecha_dato', 'ncodpers', 'pais_residencia', 'sexo', 'age',\n",
       "       'fecha_alta', 'ind_nuevo', 'antiguedad', 'indrel', 'indrel_1mes',\n",
       "       'tiprel_1mes', 'indresi', 'indext', 'canal_entrada', 'indfall',\n",
       "       'cod_prov', 'ind_actividad_cliente', 'renta', 'segmento'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1', 'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1', 'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1', 'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1', 'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1', 'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1', 'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1', 'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']\n"
     ]
    }
   ],
   "source": [
    "PROD_COLS = [col for col in df_train.columns if re.match(r\"^ind_.*_ult1$\", col)]\n",
    "print(PROD_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of prod\n",
    "df_train[\"TOTAL_PRODS\"] = df_train[PROD_COLS].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ind_ahor_fin_ult1_NEW_PUR', 'ind_aval_fin_ult1_NEW_PUR', 'ind_cco_fin_ult1_NEW_PUR', 'ind_cder_fin_ult1_NEW_PUR', 'ind_cno_fin_ult1_NEW_PUR', 'ind_ctju_fin_ult1_NEW_PUR', 'ind_ctma_fin_ult1_NEW_PUR', 'ind_ctop_fin_ult1_NEW_PUR', 'ind_ctpp_fin_ult1_NEW_PUR', 'ind_deco_fin_ult1_NEW_PUR', 'ind_deme_fin_ult1_NEW_PUR', 'ind_dela_fin_ult1_NEW_PUR', 'ind_ecue_fin_ult1_NEW_PUR', 'ind_fond_fin_ult1_NEW_PUR', 'ind_hip_fin_ult1_NEW_PUR', 'ind_plan_fin_ult1_NEW_PUR', 'ind_pres_fin_ult1_NEW_PUR', 'ind_reca_fin_ult1_NEW_PUR', 'ind_tjcr_fin_ult1_NEW_PUR', 'ind_valo_fin_ult1_NEW_PUR', 'ind_viv_fin_ult1_NEW_PUR', 'ind_nomina_ult1_NEW_PUR', 'ind_nom_pens_ult1_NEW_PUR', 'ind_recibo_ult1_NEW_PUR']\n"
     ]
    }
   ],
   "source": [
    "NEW_PUR_COLS = [col for col in df_train.columns if re.match(r\"^ind_.*_ult1_NEW_PUR$\", col)]\n",
    "print(NEW_PUR_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ind_ahor_fin_ult1_PUR_OR_CANCEL', 'ind_aval_fin_ult1_PUR_OR_CANCEL', 'ind_cco_fin_ult1_PUR_OR_CANCEL', 'ind_cder_fin_ult1_PUR_OR_CANCEL', 'ind_cno_fin_ult1_PUR_OR_CANCEL', 'ind_ctju_fin_ult1_PUR_OR_CANCEL', 'ind_ctma_fin_ult1_PUR_OR_CANCEL', 'ind_ctop_fin_ult1_PUR_OR_CANCEL', 'ind_ctpp_fin_ult1_PUR_OR_CANCEL', 'ind_deco_fin_ult1_PUR_OR_CANCEL', 'ind_deme_fin_ult1_PUR_OR_CANCEL', 'ind_dela_fin_ult1_PUR_OR_CANCEL', 'ind_ecue_fin_ult1_PUR_OR_CANCEL', 'ind_fond_fin_ult1_PUR_OR_CANCEL', 'ind_hip_fin_ult1_PUR_OR_CANCEL', 'ind_plan_fin_ult1_PUR_OR_CANCEL', 'ind_pres_fin_ult1_PUR_OR_CANCEL', 'ind_reca_fin_ult1_PUR_OR_CANCEL', 'ind_tjcr_fin_ult1_PUR_OR_CANCEL', 'ind_valo_fin_ult1_PUR_OR_CANCEL', 'ind_viv_fin_ult1_PUR_OR_CANCEL', 'ind_nomina_ult1_PUR_OR_CANCEL', 'ind_nom_pens_ult1_PUR_OR_CANCEL', 'ind_recibo_ult1_PUR_OR_CANCEL']\n"
     ]
    }
   ],
   "source": [
    "PUR_CANCEL_COLS = [col for col in df_train.columns if re.match(r\"^ind_.*_ult1_PUR_OR_CANCEL$\", col)]\n",
    "print(PUR_CANCEL_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pais_residencia', 'sexo', 'age', 'fecha_alta', 'ind_nuevo', 'antiguedad', 'indrel', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext', 'canal_entrada', 'indfall', 'cod_prov', 'ind_actividad_cliente', 'renta', 'segmento']\n"
     ]
    }
   ],
   "source": [
    "DEMOG_COLS = [col for col in df_train.columns \n",
    "    if col not in PROD_COLS + NEW_PUR_COLS + PUR_CANCEL_COLS + [\"fecha_dato\", \"ncodpers\", \"TOTAL_PRODS\"]]\n",
    "print(DEMOG_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ind_ahor_fin_ult1',\n",
       " 'ind_aval_fin_ult1',\n",
       " 'ind_cco_fin_ult1',\n",
       " 'ind_cder_fin_ult1',\n",
       " 'ind_cno_fin_ult1',\n",
       " 'ind_ctju_fin_ult1',\n",
       " 'ind_ctma_fin_ult1',\n",
       " 'ind_ctop_fin_ult1',\n",
       " 'ind_ctpp_fin_ult1',\n",
       " 'ind_deco_fin_ult1',\n",
       " 'ind_deme_fin_ult1',\n",
       " 'ind_dela_fin_ult1',\n",
       " 'ind_ecue_fin_ult1',\n",
       " 'ind_fond_fin_ult1',\n",
       " 'ind_hip_fin_ult1',\n",
       " 'ind_plan_fin_ult1',\n",
       " 'ind_pres_fin_ult1',\n",
       " 'ind_reca_fin_ult1',\n",
       " 'ind_tjcr_fin_ult1',\n",
       " 'ind_valo_fin_ult1',\n",
       " 'ind_viv_fin_ult1',\n",
       " 'ind_nomina_ult1',\n",
       " 'ind_nom_pens_ult1',\n",
       " 'ind_recibo_ult1',\n",
       " 'ind_ahor_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_aval_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_cco_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_cder_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_cno_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_ctju_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_ctma_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_ctop_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_ctpp_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_deco_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_deme_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_dela_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_ecue_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_fond_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_hip_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_plan_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_pres_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_reca_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_tjcr_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_valo_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_viv_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_nomina_ult1_PUR_OR_CANCEL',\n",
       " 'ind_nom_pens_ult1_PUR_OR_CANCEL',\n",
       " 'ind_recibo_ult1_PUR_OR_CANCEL',\n",
       " 'ind_nuevo',\n",
       " 'antiguedad',\n",
       " 'indrel',\n",
       " 'tiprel_1mes',\n",
       " 'ind_actividad_cliente',\n",
       " 'renta',\n",
       " 'segmento',\n",
       " 'TOTAL_PRODS']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEMOG_LAG_COLS = [\"ind_nuevo\", \"antiguedad\", \"indrel\", \"tiprel_1mes\", \n",
    "            \"ind_actividad_cliente\", \"renta\", \"segmento\", \"TOTAL_PRODS\"]\n",
    "\n",
    "LAG_COLS = PROD_COLS + PUR_CANCEL_COLS + DEMOG_LAG_COLS\n",
    "LAG_COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subset(df, row_filter, cols):\n",
    "    return df.loc[row_filter, cols]\n",
    "\n",
    "\n",
    "\n",
    "def suffixing_cols(df, suffix=\"_LAG\", exclude_cols=[\"ncodpers\"]):\n",
    "    new_cols = [col + suffix if col not in exclude_cols else col for col in df.columns]\n",
    "    df.columns = new_cols \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def extract_by_timestamp_newpur(df, timestamp, sel_prod_cols, \n",
    "                                new_pur_suffix=\"_NEW_PUR\", \n",
    "                                sel_cols=DEMOG_COLS):\n",
    "    \"\"\"extract rows by timestamp and new purchase columns\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    if \"ncodpers\" not in sel_cols:\n",
    "        sel_cols = [\"ncodpers\"] + sel_cols\n",
    "    \n",
    "    extracted_dfs = []\n",
    "    targets = []\n",
    "    for prod_col in sel_prod_cols:\n",
    "        pur_col = prod_col + new_pur_suffix\n",
    "        row_filter = (df[\"fecha_dato\"] == timestamp) & (df[pur_col] == 1)\n",
    "        \n",
    "        sub_df = extract_subset(df, row_filter, sel_cols)\n",
    "        #print(\"sub_df.shape:\", sub_df.shape)\n",
    "        extracted_dfs.append(sub_df)\n",
    "        \n",
    "        ys = [prod_col] * sub_df.shape[0]\n",
    "        targets.extend(ys)\n",
    "    \n",
    "    extracted_dfs = pd.concat(extracted_dfs, axis=0).reset_index(drop=True)\n",
    "    extracted_dfs[\"TARGET\"] = targets\n",
    "    \n",
    "    extracted_dfs = extracted_dfs.sort_values(by=\"ncodpers\")\n",
    "    return extracted_dfs\n",
    "\n",
    "\n",
    "def extract_by_timestamp_custid(df, timestamp, customer_ids, sel_cols):\n",
    "    df = df.copy()\n",
    "    \n",
    "    customer_ids = np.unique(customer_ids)\n",
    "    \n",
    "    if \"ncodpers\" not in sel_cols:\n",
    "        sel_cols = [\"ncodpers\"] + sel_cols\n",
    "    #print(\"sel_cols:\", sel_cols)\n",
    "    \n",
    "    row_filter = (df[\"fecha_dato\"] == timestamp) & df[\"ncodpers\"].isin(customer_ids)\n",
    "    df_out = extract_subset(df, row_filter, sel_cols)\n",
    "    return df_out\n",
    "\n",
    "\n",
    "def extract_X_y_train(df, timestamp, timestamp_lags, sel_prod_cols,\n",
    "                      demog_cols=DEMOG_COLS, lag_cols=LAG_COLS):\n",
    "    out_df = extract_by_timestamp_newpur(df, timestamp, sel_prod_cols, sel_cols=demog_cols)\n",
    "    \n",
    "    customer_ids = out_df[\"ncodpers\"]\n",
    "    for t, lag in enumerate(timestamp_lags):\n",
    "        assert pd.to_datetime(lag) < pd.to_datetime(timestamp), lag + \" lag is not before timestamp \" +  timestamp\n",
    "        lag_label = \"_LAG%d\" % (t + 1)\n",
    "        \n",
    "        lag_df = extract_by_timestamp_custid(df, lag, customer_ids=customer_ids, sel_cols=lag_cols)\n",
    "        lag_df = suffixing_cols(lag_df, lag_label, exclude_cols=[\"ncodpers\"])\n",
    "        \n",
    "        print(lag, lag_label, lag_df.shape)\n",
    "        \n",
    "        out_df = out_df.merge(lag_df, how=\"left\", on=\"ncodpers\")\n",
    "    return out_df\n",
    "\n",
    "\n",
    "def extract_X_test(train, test, timestamp, timestamp_lags, demog_cols=DEMOG_COLS, lag_cols=LAG_COLS):\n",
    "    customer_ids = test[\"ncodpers\"]\n",
    "    out_df = extract_by_timestamp_custid(test, timestamp, customer_ids=customer_ids, sel_cols=demog_cols)\n",
    "    \n",
    "    for t, lag in enumerate(timestamp_lags):\n",
    "        assert pd.to_datetime(lag) < pd.to_datetime(timestamp), lag + \" lag is not before timestamp \" +  timestamp\n",
    "        lag_label = \"_LAG%d\" % (t + 1)\n",
    "        \n",
    "        lag_df = extract_by_timestamp_custid(train, lag, customer_ids=customer_ids, sel_cols=lag_cols)\n",
    "        lag_df = suffixing_cols(lag_df, lag_label, exclude_cols=[\"ncodpers\"])\n",
    "        \n",
    "        print(lag, lag_label, lag_df.shape)\n",
    "        \n",
    "        out_df = out_df.merge(lag_df, how=\"left\", on=\"ncodpers\")\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_popular_purchase(df, timestamps, pur_cols, suffix=\"_NEW_PUR\", threshold=None):\n",
    "    assert isinstance(timestamps, list), \"timestamps must be a list\"\n",
    "    prod_popul = df.loc[df[\"fecha_dato\"].isin(timestamps), pur_cols].sum(axis=0)\n",
    "    prod_popul = prod_popul.sort_values(ascending=False)\n",
    "    prod_popul.index = [idx.replace(suffix, \"\") for idx in prod_popul.index]\n",
    "    prod_popul = prod_popul[prod_popul > 0]\n",
    "    \n",
    "    if threshold is None:\n",
    "        index = prod_popul.index\n",
    "    else:\n",
    "        index = prod_popul.index[:threshold]\n",
    "    return prod_popul[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2015-01-28T00:00:00.000000000', '2015-02-28T00:00:00.000000000',\n",
       "       '2015-03-28T00:00:00.000000000', '2015-04-28T00:00:00.000000000',\n",
       "       '2015-05-28T00:00:00.000000000', '2015-06-28T00:00:00.000000000',\n",
       "       '2015-07-28T00:00:00.000000000', '2015-08-28T00:00:00.000000000',\n",
       "       '2015-09-28T00:00:00.000000000', '2015-10-28T00:00:00.000000000',\n",
       "       '2015-11-28T00:00:00.000000000', '2015-12-28T00:00:00.000000000',\n",
       "       '2016-01-28T00:00:00.000000000', '2016-02-28T00:00:00.000000000',\n",
       "       '2016-03-28T00:00:00.000000000', '2016-04-28T00:00:00.000000000',\n",
       "       '2016-05-28T00:00:00.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"fecha_dato\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lags up to 6 months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract `X_test` at `2016_06`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-28 _LAG1 (929615, 57)\n",
      "2016-04-28 _LAG2 (925252, 57)\n",
      "2016-03-28 _LAG3 (920975, 57)\n",
      "2016-02-28 _LAG4 (915679, 57)\n",
      "2016-01-28 _LAG5 (909885, 57)\n",
      "2015-12-28 _LAG6 (903429, 57)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(929615, 354)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp = \"2016-06-28\"\n",
    "timestamp_lags = [\"2016-05-28\", \"2016-04-28\", \"2016-03-28\", \"2016-02-28\", \"2016-01-28\",\n",
    "                  \"2015-12-28\"]\n",
    "\n",
    "X_test = extract_X_test(df_train, df_test, timestamp, timestamp_lags)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(os.path.join(OUT_DIR1, \"X_test.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract `X` and `y` for training set from `2015-07` to `2016-04`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = [\"2016-04-28\", \"2016-03-28\", \"2016-02-28\", \"2016-01-28\", \n",
    "              \"2015-12-28\", \"2015-11-28\", \"2015-10-28\", \"2015-09-28\", \n",
    "              \"2015-08-28\", \"2015-07-28\"]\n",
    "\n",
    "\n",
    "lags = {}\n",
    "lags[\"2016-04-28\"] = [\"2016-03-28\", \"2016-02-28\", \"2016-01-28\", \"2015-12-28\", \"2015-11-28\", \"2015-10-28\"]\n",
    "\n",
    "lags[\"2016-03-28\"] = [\"2016-02-28\", \"2016-01-28\", \"2015-12-28\", \"2015-11-28\", \"2015-10-28\", \"2015-09-28\"]\n",
    "\n",
    "lags[\"2016-02-28\"] = [\"2016-01-28\", \"2015-12-28\", \"2015-11-28\", \"2015-10-28\", \"2015-09-28\", \"2015-08-28\"]\n",
    "\n",
    "lags[\"2016-01-28\"] = [\"2015-12-28\", \"2015-11-28\", \"2015-10-28\", \"2015-09-28\", \"2015-08-28\", \"2015-07-28\"]\n",
    "\n",
    "lags[\"2015-12-28\"] = [\"2015-11-28\", \"2015-10-28\", \"2015-09-28\", \"2015-08-28\", \"2015-07-28\", \"2015-06-28\"]\n",
    "\n",
    "lags[\"2015-11-28\"] = [\"2015-10-28\", \"2015-09-28\", \"2015-08-28\", \"2015-07-28\", \"2015-06-28\", \"2015-05-28\"]\n",
    "\n",
    "lags[\"2015-10-28\"] = [\"2015-09-28\", \"2015-08-28\", \"2015-07-28\", \"2015-06-28\", \"2015-05-28\", \"2015-04-28\"]\n",
    "\n",
    "lags[\"2015-09-28\"] = [\"2015-08-28\", \"2015-07-28\", \"2015-06-28\", \"2015-05-28\", \"2015-04-28\", \"2015-03-28\"]\n",
    "\n",
    "lags[\"2015-08-28\"] = [\"2015-07-28\", \"2015-06-28\", \"2015-05-28\", \"2015-04-28\", \"2015-03-28\", \"2015-02-28\"]\n",
    "\n",
    "lags[\"2015-07-28\"] = [\"2015-06-28\", \"2015-05-28\", \"2015-04-28\", \"2015-03-28\", \"2015-02-28\", \"2015-01-28\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "ind_recibo_ult1      101135\n",
      "ind_nom_pens_ult1     51994\n",
      "ind_cco_fin_ult1      50031\n",
      "ind_nomina_ult1       47049\n",
      "ind_tjcr_fin_ult1     43012\n",
      "ind_cno_fin_ult1      25382\n",
      "ind_ecue_fin_ult1     16469\n",
      "ind_dela_fin_ult1      8494\n",
      "ind_ctma_fin_ult1      5271\n",
      "ind_reca_fin_ult1      4378\n",
      "ind_valo_fin_ult1      3655\n",
      "ind_ctop_fin_ult1      2335\n",
      "ind_fond_fin_ult1      1479\n",
      "ind_ctpp_fin_ult1      1461\n",
      "ind_deco_fin_ult1      1451\n",
      "ind_plan_fin_ult1       483\n",
      "ind_ctju_fin_ult1       396\n",
      "ind_deme_fin_ult1       110\n",
      "ind_pres_fin_ult1        83\n",
      "ind_cder_fin_ult1        76\n",
      "ind_hip_fin_ult1         43\n",
      "ind_viv_fin_ult1         39\n",
      "ind_aval_fin_ult1         1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "popul_pur = most_popular_purchase(df_train, timestamps, NEW_PUR_COLS)\n",
    "print(len(popul_pur))\n",
    "print(popul_pur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "['ind_recibo_ult1', 'ind_nom_pens_ult1', 'ind_cco_fin_ult1', 'ind_nomina_ult1', 'ind_tjcr_fin_ult1', 'ind_cno_fin_ult1', 'ind_ecue_fin_ult1', 'ind_dela_fin_ult1', 'ind_ctma_fin_ult1', 'ind_reca_fin_ult1', 'ind_valo_fin_ult1', 'ind_ctop_fin_ult1', 'ind_fond_fin_ult1', 'ind_ctpp_fin_ult1', 'ind_deco_fin_ult1', 'ind_plan_fin_ult1', 'ind_ctju_fin_ult1', 'ind_deme_fin_ult1', 'ind_pres_fin_ult1', 'ind_cder_fin_ult1', 'ind_hip_fin_ult1', 'ind_viv_fin_ult1']\n"
     ]
    }
   ],
   "source": [
    "# take 22 most popular product\n",
    "Y_LABES = popul_pur[:22].index\n",
    "Y_LABES = list(Y_LABES)\n",
    "print(len(Y_LABES))\n",
    "print(Y_LABES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract X and y for 2016-04-28\n",
      "2016-03-28 _LAG1 (26736, 57)\n",
      "2016-02-28 _LAG2 (25051, 57)\n",
      "2016-01-28 _LAG3 (24255, 57)\n",
      "2015-12-28 _LAG4 (23556, 57)\n",
      "2015-11-28 _LAG5 (22805, 57)\n",
      "2015-10-28 _LAG6 (22308, 57)\n",
      "X_y.shape (33022, 355)\n",
      "X_y.isnull().sum().sum() 1156176\n",
      "\n",
      "Extract X and y for 2016-03-28\n",
      "2016-02-28 _LAG1 (27735, 57)\n",
      "2016-01-28 _LAG2 (25523, 57)\n",
      "2015-12-28 _LAG3 (24550, 57)\n",
      "2015-11-28 _LAG4 (23965, 57)\n",
      "2015-10-28 _LAG5 (23279, 57)\n",
      "2015-09-28 _LAG6 (22699, 57)\n",
      "X_y.shape (35258, 355)\n",
      "X_y.isnull().sum().sum() 1357608\n",
      "\n",
      "Extract X and y for 2016-02-28\n",
      "2016-01-28 _LAG1 (36071, 57)\n",
      "2015-12-28 _LAG2 (33896, 57)\n",
      "2015-11-28 _LAG3 (33001, 57)\n",
      "2015-10-28 _LAG4 (32247, 57)\n",
      "2015-09-28 _LAG5 (31246, 57)\n",
      "2015-08-28 _LAG6 (30582, 57)\n",
      "X_y.shape (49072, 355)\n",
      "X_y.isnull().sum().sum() 1417920\n",
      "\n",
      "Extract X and y for 2016-01-28\n",
      "2015-12-28 _LAG1 (26268, 57)\n",
      "2015-11-28 _LAG2 (24517, 57)\n",
      "2015-10-28 _LAG3 (23657, 57)\n",
      "2015-09-28 _LAG4 (22854, 57)\n",
      "2015-08-28 _LAG5 (22040, 57)\n",
      "2015-07-28 _LAG6 (21610, 57)\n",
      "X_y.shape (31031, 355)\n",
      "X_y.isnull().sum().sum() 1179528\n",
      "\n",
      "Extract X and y for 2015-12-28\n",
      "2015-11-28 _LAG1 (33684, 57)\n",
      "2015-10-28 _LAG2 (31219, 57)\n",
      "2015-09-28 _LAG3 (30180, 57)\n",
      "2015-08-28 _LAG4 (29313, 57)\n",
      "2015-07-28 _LAG5 (28619, 57)\n",
      "2015-06-28 _LAG6 (27134, 57)\n",
      "X_y.shape (42385, 355)\n",
      "X_y.isnull().sum().sum() 1609832\n",
      "\n",
      "Extract X and y for 2015-11-28\n",
      "2015-10-28 _LAG1 (28036, 57)\n",
      "2015-09-28 _LAG2 (25122, 57)\n",
      "2015-08-28 _LAG3 (24120, 57)\n",
      "2015-07-28 _LAG4 (23473, 57)\n",
      "2015-06-28 _LAG5 (21863, 57)\n",
      "2015-05-28 _LAG6 (21650, 57)\n",
      "X_y.shape (35266, 355)\n",
      "X_y.isnull().sum().sum() 1693048\n",
      "\n",
      "Extract X and y for 2015-10-28\n",
      "2015-09-28 _LAG1 (32208, 57)\n",
      "2015-08-28 _LAG2 (28559, 57)\n",
      "2015-07-28 _LAG3 (27894, 57)\n",
      "2015-06-28 _LAG4 (26249, 57)\n",
      "2015-05-28 _LAG5 (25881, 57)\n",
      "2015-04-28 _LAG6 (25585, 57)\n",
      "X_y.shape (39834, 355)\n",
      "X_y.isnull().sum().sum() 1795248\n",
      "\n",
      "Extract X and y for 2015-09-28\n",
      "2015-08-28 _LAG1 (28479, 57)\n",
      "2015-07-28 _LAG2 (26569, 57)\n",
      "2015-06-28 _LAG3 (24817, 57)\n",
      "2015-05-28 _LAG4 (24429, 57)\n",
      "2015-04-28 _LAG5 (23988, 57)\n",
      "2015-03-28 _LAG6 (23710, 57)\n",
      "X_y.shape (35731, 355)\n",
      "X_y.isnull().sum().sum() 1308216\n",
      "\n",
      "Extract X and y for 2015-08-28\n",
      "2015-07-28 _LAG1 (24326, 57)\n",
      "2015-06-28 _LAG2 (19680, 57)\n",
      "2015-05-28 _LAG3 (19366, 57)\n",
      "2015-04-28 _LAG4 (18979, 57)\n",
      "2015-03-28 _LAG5 (18577, 57)\n",
      "2015-02-28 _LAG6 (18326, 57)\n",
      "X_y.shape (29514, 355)\n",
      "X_y.isnull().sum().sum() 1721104\n",
      "\n",
      "Extract X and y for 2015-07-28\n",
      "2015-06-28 _LAG1 (26097, 57)\n",
      "2015-05-28 _LAG2 (25296, 57)\n",
      "2015-04-28 _LAG3 (24887, 57)\n",
      "2015-03-28 _LAG4 (24460, 57)\n",
      "2015-02-28 _LAG5 (23935, 57)\n",
      "2015-01-28 _LAG6 (23579, 57)\n",
      "X_y.shape (33713, 355)\n",
      "X_y.isnull().sum().sum() 768824\n",
      "\n",
      "X_y_train.shape (364826, 355)\n",
      "X_y_train.isnull().sum().sum() 14007504\n"
     ]
    }
   ],
   "source": [
    "X_y_train = []\n",
    "for timestamp in timestamps:\n",
    "    print(\"Extract X and y for \" + timestamp)\n",
    "    timestamp_lags = lags[timestamp]\n",
    "    \n",
    "    X_y = extract_X_y_train(df_train, timestamp, timestamp_lags, Y_LABES)\n",
    "    print(\"X_y.shape\", X_y.shape)\n",
    "    print(\"X_y.isnull().sum().sum()\", X_y.isnull().sum().sum())\n",
    "    print(\"\")\n",
    "    X_y_train.append(X_y)\n",
    "\n",
    "X_y_train = pd.concat(X_y_train, axis=0)\n",
    "print(\"X_y_train.shape\", X_y_train.shape)\n",
    "print(\"X_y_train.isnull().sum().sum()\", X_y_train.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y_train.to_csv(os.path.join(OUT_DIR1, \"X_y_train.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract `X` and `y` for validation set at `2016_05`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-04-28 _LAG1 (27874, 57)\n",
      "2016-03-28 _LAG2 (26371, 57)\n",
      "2016-02-28 _LAG3 (25691, 57)\n",
      "2016-01-28 _LAG4 (24935, 57)\n",
      "2015-12-28 _LAG5 (23967, 57)\n",
      "2015-11-28 _LAG6 (23552, 57)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(35887, 355)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp = \"2016-05-28\"\n",
    "timestamp_lags = [\"2016-04-28\", \"2016-03-28\", \"2016-02-28\", \"2016-01-28\", \"2015-12-28\", \"2015-11-28\"]\n",
    "\n",
    "X_y_val = extract_X_y_train(df_train, timestamp, timestamp_lags, Y_LABES)\n",
    "X_y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y_val.to_csv(os.path.join(OUT_DIR1, \"X_y_val.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lags up to 3 months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract `X_test` at `2016_06`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-28 _LAG1 (929615, 57)\n",
      "2016-04-28 _LAG2 (925252, 57)\n",
      "2016-03-28 _LAG3 (920975, 57)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(929615, 186)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp = \"2016-06-28\"\n",
    "timestamp_lags = [\"2016-05-28\", \"2016-04-28\", \"2016-03-28\"]\n",
    "\n",
    "X_test = extract_X_test(df_train, df_test, timestamp, timestamp_lags)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(os.path.join(OUT_DIR2, \"X_test.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract `X` and `y` for training set from `2015-04` to `2016-04`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = [\"2016-04-28\", \"2016-03-28\", \"2016-02-28\", \"2016-01-28\", \n",
    "              \"2015-12-28\", \"2015-11-28\", \"2015-10-28\", \"2015-09-28\", \n",
    "              \"2015-08-28\", \"2015-07-28\", \"2015-06-28\", \"2015-05-28\", \"2015-04-28\"]\n",
    "\n",
    "\n",
    "lags = {}\n",
    "lags[\"2016-04-28\"] = [\"2016-03-28\", \"2016-02-28\", \"2016-01-28\"]\n",
    "\n",
    "lags[\"2016-03-28\"] = [\"2016-02-28\", \"2016-01-28\", \"2015-12-28\"]\n",
    "\n",
    "lags[\"2016-02-28\"] = [\"2016-01-28\", \"2015-12-28\", \"2015-11-28\"]\n",
    "\n",
    "lags[\"2016-01-28\"] = [\"2015-12-28\", \"2015-11-28\", \"2015-10-28\"]\n",
    "\n",
    "lags[\"2015-12-28\"] = [\"2015-11-28\", \"2015-10-28\", \"2015-09-28\"]\n",
    "\n",
    "lags[\"2015-11-28\"] = [\"2015-10-28\", \"2015-09-28\", \"2015-08-28\"]\n",
    "\n",
    "lags[\"2015-10-28\"] = [\"2015-09-28\", \"2015-08-28\", \"2015-07-28\"]\n",
    "\n",
    "lags[\"2015-09-28\"] = [\"2015-08-28\", \"2015-07-28\", \"2015-06-28\"]\n",
    "\n",
    "lags[\"2015-08-28\"] = [\"2015-07-28\", \"2015-06-28\", \"2015-05-28\"]\n",
    "\n",
    "lags[\"2015-07-28\"] = [\"2015-06-28\", \"2015-05-28\", \"2015-04-28\"]\n",
    "\n",
    "lags[\"2015-06-28\"] = [\"2015-05-28\", \"2015-04-28\", \"2015-03-28\"]\n",
    "\n",
    "lags[\"2015-05-28\"] = [\"2015-04-28\", \"2015-03-28\", \"2015-02-28\"]\n",
    "\n",
    "lags[\"2015-04-28\"] = [\"2015-03-28\", \"2015-02-28\", \"2015-01-28\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "ind_recibo_ult1      125617\n",
      "ind_nom_pens_ult1     69125\n",
      "ind_cco_fin_ult1      61631\n",
      "ind_nomina_ult1       58173\n",
      "ind_tjcr_fin_ult1     56491\n",
      "ind_cno_fin_ult1      31165\n",
      "ind_ecue_fin_ult1     20599\n",
      "ind_dela_fin_ult1     11117\n",
      "ind_reca_fin_ult1      8525\n",
      "ind_ctma_fin_ult1      5907\n",
      "ind_valo_fin_ult1      4203\n",
      "ind_ctop_fin_ult1      3122\n",
      "ind_fond_fin_ult1      2617\n",
      "ind_deco_fin_ult1      2244\n",
      "ind_ctpp_fin_ult1      1952\n",
      "ind_plan_fin_ult1       545\n",
      "ind_ctju_fin_ult1       425\n",
      "ind_deme_fin_ult1       194\n",
      "ind_pres_fin_ult1       119\n",
      "ind_cder_fin_ult1       104\n",
      "ind_hip_fin_ult1         60\n",
      "ind_viv_fin_ult1         51\n",
      "ind_aval_fin_ult1         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "popul_pur = most_popular_purchase(df_train, timestamps, NEW_PUR_COLS)\n",
    "print(len(popul_pur))\n",
    "print(popul_pur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "['ind_recibo_ult1', 'ind_nom_pens_ult1', 'ind_cco_fin_ult1', 'ind_nomina_ult1', 'ind_tjcr_fin_ult1', 'ind_cno_fin_ult1', 'ind_ecue_fin_ult1', 'ind_dela_fin_ult1', 'ind_reca_fin_ult1', 'ind_ctma_fin_ult1', 'ind_valo_fin_ult1', 'ind_ctop_fin_ult1', 'ind_fond_fin_ult1', 'ind_deco_fin_ult1', 'ind_ctpp_fin_ult1', 'ind_plan_fin_ult1', 'ind_ctju_fin_ult1', 'ind_deme_fin_ult1', 'ind_pres_fin_ult1', 'ind_cder_fin_ult1', 'ind_hip_fin_ult1', 'ind_viv_fin_ult1']\n"
     ]
    }
   ],
   "source": [
    "# take 22 most popular product\n",
    "Y_LABES = popul_pur[:22].index\n",
    "Y_LABES = list(Y_LABES)\n",
    "print(len(Y_LABES))\n",
    "print(Y_LABES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract X and y for 2016-04-28\n",
      "2016-03-28 _LAG1 (26736, 57)\n",
      "2016-02-28 _LAG2 (25051, 57)\n",
      "2016-01-28 _LAG3 (24255, 57)\n",
      "X_y.shape (33022, 187)\n",
      "X_y.isnull().sum().sum() 313376\n",
      "\n",
      "Extract X and y for 2016-03-28\n",
      "2016-02-28 _LAG1 (27735, 57)\n",
      "2016-01-28 _LAG2 (25523, 57)\n",
      "2015-12-28 _LAG3 (24550, 57)\n",
      "X_y.shape (35258, 187)\n",
      "X_y.isnull().sum().sum() 393736\n",
      "\n",
      "Extract X and y for 2016-02-28\n",
      "2016-01-28 _LAG1 (36071, 57)\n",
      "2015-12-28 _LAG2 (33896, 57)\n",
      "2015-11-28 _LAG3 (33001, 57)\n",
      "X_y.shape (49072, 187)\n",
      "X_y.isnull().sum().sum() 387408\n",
      "\n",
      "Extract X and y for 2016-01-28\n",
      "2015-12-28 _LAG1 (26268, 57)\n",
      "2015-11-28 _LAG2 (24517, 57)\n",
      "2015-10-28 _LAG3 (23657, 57)\n",
      "X_y.shape (31031, 187)\n",
      "X_y.isnull().sum().sum() 316848\n",
      "\n",
      "Extract X and y for 2015-12-28\n",
      "2015-11-28 _LAG1 (33684, 57)\n",
      "2015-10-28 _LAG2 (31219, 57)\n",
      "2015-09-28 _LAG3 (30180, 57)\n",
      "X_y.shape (42385, 187)\n",
      "X_y.isnull().sum().sum() 439320\n",
      "\n",
      "Extract X and y for 2015-11-28\n",
      "2015-10-28 _LAG1 (28036, 57)\n",
      "2015-09-28 _LAG2 (25122, 57)\n",
      "2015-08-28 _LAG3 (24120, 57)\n",
      "X_y.shape (35266, 187)\n",
      "X_y.isnull().sum().sum() 484512\n",
      "\n",
      "Extract X and y for 2015-10-28\n",
      "2015-09-28 _LAG1 (32208, 57)\n",
      "2015-08-28 _LAG2 (28559, 57)\n",
      "2015-07-28 _LAG3 (27894, 57)\n",
      "X_y.shape (39834, 187)\n",
      "X_y.isnull().sum().sum() 526176\n",
      "\n",
      "Extract X and y for 2015-09-28\n",
      "2015-08-28 _LAG1 (28479, 57)\n",
      "2015-07-28 _LAG2 (26569, 57)\n",
      "2015-06-28 _LAG3 (24817, 57)\n",
      "X_y.shape (35731, 187)\n",
      "X_y.isnull().sum().sum() 385952\n",
      "\n",
      "Extract X and y for 2015-08-28\n",
      "2015-07-28 _LAG1 (24326, 57)\n",
      "2015-06-28 _LAG2 (19680, 57)\n",
      "2015-05-28 _LAG3 (19366, 57)\n",
      "X_y.shape (29514, 187)\n",
      "X_y.isnull().sum().sum() 610176\n",
      "\n",
      "Extract X and y for 2015-07-28\n",
      "2015-06-28 _LAG1 (26097, 57)\n",
      "2015-05-28 _LAG2 (25296, 57)\n",
      "2015-04-28 _LAG3 (24887, 57)\n",
      "X_y.shape (33713, 187)\n",
      "X_y.isnull().sum().sum() 220584\n",
      "\n",
      "Extract X and y for 2015-06-28\n",
      "2015-05-28 _LAG1 (33318, 57)\n",
      "2015-04-28 _LAG2 (32453, 57)\n",
      "2015-03-28 _LAG3 (32052, 57)\n",
      "X_y.shape (41991, 187)\n",
      "X_y.isnull().sum().sum() 207872\n",
      "\n",
      "Extract X and y for 2015-05-28\n",
      "2015-04-28 _LAG1 (21203, 57)\n",
      "2015-03-28 _LAG2 (20484, 57)\n",
      "2015-02-28 _LAG3 (20057, 57)\n",
      "X_y.shape (26553, 187)\n",
      "X_y.isnull().sum().sum() 184968\n",
      "\n",
      "Extract X and y for 2015-04-28\n",
      "2015-03-28 _LAG1 (25496, 57)\n",
      "2015-02-28 _LAG2 (24621, 57)\n",
      "2015-01-28 _LAG3 (24140, 57)\n",
      "X_y.shape (30616, 187)\n",
      "X_y.isnull().sum().sum() 203224\n",
      "\n",
      "X_y_train.shape (463986, 187)\n",
      "X_y_train.isnull().sum().sum() 4674152\n"
     ]
    }
   ],
   "source": [
    "X_y_train = []\n",
    "for timestamp in timestamps:\n",
    "    print(\"Extract X and y for \" + timestamp)\n",
    "    timestamp_lags = lags[timestamp]\n",
    "    \n",
    "    X_y = extract_X_y_train(df_train, timestamp, timestamp_lags, Y_LABES)\n",
    "    print(\"X_y.shape\", X_y.shape)\n",
    "    print(\"X_y.isnull().sum().sum()\", X_y.isnull().sum().sum())\n",
    "    print(\"\")\n",
    "    X_y_train.append(X_y)\n",
    "\n",
    "X_y_train = pd.concat(X_y_train, axis=0)\n",
    "print(\"X_y_train.shape\", X_y_train.shape)\n",
    "print(\"X_y_train.isnull().sum().sum()\", X_y_train.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y_train.to_csv(os.path.join(OUT_DIR2, \"X_y_train.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract `X` and `y` for validation set at `2016_05`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-04-28 _LAG1 (27874, 57)\n",
      "2016-03-28 _LAG2 (26371, 57)\n",
      "2016-02-28 _LAG3 (25691, 57)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(35887, 187)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp = \"2016-05-28\"\n",
    "timestamp_lags = [\"2016-04-28\", \"2016-03-28\", \"2016-02-28\"]\n",
    "\n",
    "X_y_val = extract_X_y_train(df_train, timestamp, timestamp_lags, Y_LABES)\n",
    "X_y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y_val.to_csv(os.path.join(OUT_DIR2, \"X_y_val.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
